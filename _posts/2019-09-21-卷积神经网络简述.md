---
layout:     post
title:      卷积神经网络简述

subtitle:   卷积神经网络二
date:       2019-09-21
author:     RongrongYa
header-img: img/post-bg-debug.png
catalog: true
tags:
    - DL
    - ML/CNN
  
---

> 上一篇 ▶️ [《卷积神经网络》（第一篇）](https://zhaoylong.github.io/2019/05/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0/)

# 前言
时间隔了好久的亚子......    
都忘记了......

## 4 池化（pooling）层

### 4.1 简述
通过卷积获得特征[features]后，下一步将利用获取的特征去做分类。但面临着计算了庞大的挑战。例如：一个$96 \times 96$像素的图像，假设我们已经学习得到了400个定义在$8 \times 8$输入上的特征，每一个特征和图像卷积都会得到一个$(96-8+1) \times (96-8+1) = 7921$维的特征，由于有400个特征，所以每个样本例[example]都会得到一个$89^2 \times 400 = 3168400$维的卷积特征向量。当特征N非常大时，非常难以计算，且易出现过拟[over-fitting]。注：每个卷积模版生成一个特征，每个特征是$89^2$维。

为了解决这个问题，采取了一种叫做“池化”的操作，平均池化或者最大池化。

若选择图像中连续范围作为池化区域，并且只是池化相同的隐藏单元产生的特征，那么这些池化单元就具有平移不变性[translationinvariant]。

- 形式化描述：
  - 在获取到卷积特征后，确定池化区域的大小，来池化卷积特征。将卷积特征划分到数个大小相等不相交的区域，取该区域的平均值或者最大值来表示该区域的特征。池化后的特征便可以用来做分类。

## 4.2 pooling层的实现方法
CNN中，卷积层后接pooling层。pooling层对卷积层输出信息进行简化。与卷积层类似，需要指定池化区域的大小和步长。   
- 假定输入特征的大小维$h \times w$
- 池化区域的大小维$f \times f$
- 步长为$s$
则池化运算的输出大小为：        
$$
h^{'} = \lfloor \frac{h-f+s}{s} \rfloor \\
w^{'} = \lfloor \frac{w-f+s}{s} \rfloor
$$
例如，当输入特征a为 <br/>     
$$
a = \begin{pmatrix}
    1 & 3 & 0 & -1 \\
    -2 & 0 & 3 & 2 \\
    2 & -3 & -1 & 4 \\
    4 & 2 & 0 & 1
\end{pmatrix}
$$    
以$2 \times 2$为pooling区域大小、步长为1时的max-pooling运算过程。得到的池化输出为：      
$$
\begin{pmatrix}
    3&3&3 \\
    2&3&4 \\
    4&2&4
\end{pmatrix}
$$    

池化操作可有效地对输入的特征实现采样，从而获得紧凑的特征表示。去除那些不显著的特征位置，从而进一步减少了参数个数。

<p style="text-align:center">Max pooling 运算示意图</p>   
![Max-pooling](/img/pool_img_02.jpg)

由于卷积层包含多个特征映射[一个映射对应一个卷积滤波器]，max-pooling需要应用于每个特征映射。若包含是那个特征映射的池化过程，会得到三个max池化输出。

<p style="text-align:center">CNN手绘图</p>
![个人听课记录](/img/pooling_img_01.jpg)

## 5 全连接层
在CNN架构的末端是全连接层，即在全连接层中的每一个节点与上一层所有节点都连接。全连接层可以有多个，这类似于前馈神经网络中的隐藏层，然后连接到输出层，如含有Softmax、SVM的输出层，完成分类任务。

## 6 简化架构CNN的训练方法
CNN可以包含多个层，这些层主要包括下面三种：卷积层、Pooling、全连接层。

所谓简化，指的是卷积层的每个输出特征只使用一个卷积滤波器与前一层的一个输出生成。训练方法则分为信息的正向传播和反向传播过程。

### 6.1 卷积层[Convolution Layers]
 
